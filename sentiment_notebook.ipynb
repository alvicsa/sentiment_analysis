{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "## Overview\n",
    "\n",
    "The focus of this exercise is on a field within machine learning called [Natural Language Processing](https://en.wikipedia.org/wiki/Natural-language_processing). We can think of this field as the intersection between language, and machine learning. Tasks in this field include automatic translation (Google translate), intelligent personal assistants (Siri), information extraction, and speech recognition for example.\n",
    "\n",
    "NLP uses many of the same techniques as traditional data science, but also features a number of specialised skills and approaches. There is no expectation that you have any experience with NLP, however, to complete the challenge it will be useful to have the following skills:\n",
    "\n",
    "- understanding of the python programming language\n",
    "- understanding of basic machine learning concepts, i.e. supervised learning\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Download this notebook!\n",
    "2. Answer each of the provided questions, including your source code as cells in this notebook.\n",
    "3. Share the results with us, e.g. a Github repo.\n",
    "\n",
    "### Task description\n",
    "\n",
    "You will be performing a task known as [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). Here, the goal is to predict sentiment -- the emotional intent behind a statement -- from text. For example, the sentence: \"*This movie was terrible!\"* has a negative sentiment, whereas \"*loved this cinematic masterpiece*\" has a positive sentiment.\n",
    "\n",
    "To simplify the task, we consider sentiment binary: labels of `1` indicate a sentence has a positive sentiment, and labels of `0` indicate that the sentence has a negative sentiment.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset is split across three files, representing three different sources -- Amazon, Yelp and IMDB. Your task is to build a sentiment analysis model using both the Yelp and IMDB data as your training-set, and test the performance of your model on the Amazon data.\n",
    "\n",
    "Each file can be found in the `input` directory, and contains 1000 rows of data. Each row contains a sentence, a `tab` character and then a label -- `0` or `1`. \n",
    "\n",
    "**Notes**\n",
    "- Feel free to use existing machine learning libraries as components in you solution!\n",
    "- Suggested libraries: `sklearn` (for machine learning), `pandas` (for loading/processing data), `spacy` (for text processing).\n",
    "- As mentioned, you are not expected to have previous experience with this exact task. You are free to refer to external tutorials/resources to assist you. However, you will be asked to justfify the choices you have made -- so make you understand the approach you have taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'yelp_labelled.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "### 1. Read and concatenate data into test and train sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all review data into two Pandas Data Frames representing the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set path to the data files\n",
    "path = './input/'\n",
    "\n",
    "# Add column names\n",
    "col_names = ['Text', 'Label']\n",
    "\n",
    "# Import data files as Pandas Dataframes\n",
    "df_yelp = pd.read_table(path+'yelp_labelled.txt', names=col_names)\n",
    "df_amazon = pd.read_table(path+'amazon_cells_labelled.txt', names=col_names) # Use as test dataset\n",
    "df_imdb = pd.read_table(path+'imdb_labelled.txt', names=col_names)\n",
    "\n",
    "# Combine/union Yelp and IMDB into a single dataframe\n",
    "df_comb = pd.concat([df_yelp, df_imdb])    # Use as train data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all three datasets into one and use for alternative testing\n",
    "\n",
    "df_all = pd.concat([df_yelp, df_imdb, df_amazon])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare the data for input into your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text     0\n",
       "Label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Missing Values\n",
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize and remove stop words from the obtained dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization** is the process of breaking text into pieces, called tokens, and ignoring characters like punctuation marks (,. “ ‘) and spaces. spaCy‘s tokenizer takes input in form of unicode text and outputs a sequence of token objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "\n",
    "# Build a list of stopwords to use to filter\n",
    "stopwords = list(STOP_WORDS)\n",
    "\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    mytokens = nlp(sentence)\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp(\"This is how John Walker was walking. He was also running beside the lawn.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['john', 'walker', 'walk', 'run', 'lawn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of tekonizer\n",
    "my_tokenizer(\"This is how John Walker was walking. He was also running beside the lawn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required ML Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "\n",
    "\n",
    "# Basic text cleaning function that removes spaces and converts text into lowercase\n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "\n",
    "#Custom transformer that inherits from the TransformerMixin class\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "# Bag of Words (BoW) converts text into the matrix of occurrence of words within a given document\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\n",
    "vectorizer = CountVectorizer(tokenizer = my_tokenizer, ngram_range=(1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Train and Test datasets and split into text and labels\n",
    "X_train = df_comb['Text']\n",
    "y_train = df_comb['Label']\n",
    "\n",
    "X_test = df_amazon['Text']\n",
    "y_test = df_amazon['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a: Find the ten most frequent words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokenised Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>wow ... love place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>tasty texture nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>stop late bank holiday rick steve recommendati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>selection menu great price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0                           Wow... Loved this place.      1   \n",
       "1                                 Crust is not good.      0   \n",
       "2          Not tasty and the texture was just nasty.      0   \n",
       "3  Stopped by during the late May bank holiday of...      1   \n",
       "4  The selection on the menu was great and so wer...      1   \n",
       "\n",
       "                                      Tokenised Text  \n",
       "0                                 wow ... love place  \n",
       "1                                         crust good  \n",
       "2                                tasty texture nasty  \n",
       "3  stop late bank holiday rick steve recommendati...  \n",
       "4                         selection menu great price  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comb['Tokenised Text'] = df_comb['Text'].apply(lambda x: my_tokenizer(x)).apply(lambda x: ' '.join(x))\n",
    "\n",
    "df_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie    212\n",
       "good     201\n",
       "film     189\n",
       "0        138\n",
       "food     127\n",
       "bad      126\n",
       "1        124\n",
       "place    119\n",
       "great    115\n",
       "like     111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List top 10 most frequent words from the training set\n",
    "words = pd.Series(' '.join(df_comb['Tokenised Text']).split()).value_counts()[:10]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train your model and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# Select Linear Support Vector Classification \n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x00000207A215C040>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function my_tokenizer at 0x000002079AD6F550>)),\n",
       "                ('classifier', LinearSVC())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline with three components: a cleaner, a vectorizer, and a classifier. \n",
    "# The cleaner uses our predictors class object to clean and preprocess the text. \n",
    "# The vectorizer uses countvector objects to create the bag of words matrix for our text. \n",
    "# The classifier is an object that performs the logistic regression to classify the sentiments\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit our data - Fit the model according to the given training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Predicting with a test dataset - Predict class labels for samples in X.\n",
    "# sample_prediction = pipe_countvect.predict(X_test)\n",
    "\n",
    "# Print Prediction Results\n",
    "# 1 = Positive review\n",
    "# 0 = Negative review\n",
    "# for (sample,pred) in zip(X_test,sample_prediction):\n",
    "#     print(sample,\"Prediction=>\",pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate your model using metric(s) you see fit and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Training Accuracy:  0.986\n",
      "LinearSVC Test Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Results - Accuracy - Balanced Problem\n",
    "#Return the mean accuracy on the given test data and labels.\n",
    "\n",
    "print(\"LinearSVC Training Accuracy: \", np.around(pipe.score(X_train, y_train), decimals=3))\n",
    "print(\"LinearSVC Test Accuracy: \", np.around(pipe.score(X_test, y_test), decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Notes on Accuracy:\n",
    "\n",
    "Informally, accuracy is the fraction of predictions our model got right. Accuracy alone doesn't tell the full story when you're working with a class-imbalanced data set, where there is a significant disparity between the number of positive and negative labels.\n",
    "\n",
    "To fully evaluate the effectiveness of a model, you must examine both **precision** and **recall**.\n",
    "\n",
    "![Accuracy - Precision](./images/precision.png \"Title\")\n",
    "![Accuracy - Recall](./images/recall.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Classification Accuracy: 0.75\n",
      "Support Vector Classification Precision: 0.805\n",
      "Support Vector Classification Recall: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Support Vector Classification Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"Support Vector Classification Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"Support Vector Classification Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.772\n",
      "Logistic Regression Precision: 0.845\n",
      "Logistic Regression Recall: 0.666\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Prediction model using LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Fit our data - Fit the model according to the given training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"Logistic Regression Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"Logistic Regression Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate alternative train/test model using all datasets combined and using 80-20 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Splitting data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and Labels\n",
    "X = df_all['Text']\n",
    "ylabels = df_all['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for recording the model performance\n",
    "df_performance = pd.DataFrame(columns=('Model', 'Train Accuracy', 'Test Accuracy', 'Test Precision', 'Test Recall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Applying different classification models to test performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Linear Support Vector Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Training Accuracy: 0.976\n",
      "LinearSVC Test Accuracy: 0.767\n",
      "LinearSVC Test Precision: 0.733\n",
      "LinearSVC Test Recall: 0.774\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Prediction model using LinearSVC\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', LinearSVC())])\n",
    "\n",
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Record performance\n",
    "perf_record = [{'Model': 'LinearSVC', \n",
    "         'Train Accuracy': np.around(pipe.score(X_train,y_train), decimals=3),\n",
    "         'Test Accuracy': np.around(metrics.accuracy_score(y_test, predicted), decimals=3),\n",
    "        'Test Precision': np.around(metrics.precision_score(y_test, predicted), decimals=3), \n",
    "         'Test Recall': np.around(metrics.recall_score(y_test, predicted), decimals=3)}]\n",
    "\n",
    "df_performance = df_performance.append(perf_record, ignore_index=True, sort=False)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"LinearSVC Training Accuracy:\", np.around(pipe.score(X_train,y_train), decimals=3))\n",
    "print(\"LinearSVC Test Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"LinearSVC Test Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"LinearSVC Test Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.946\n",
      "Logistic Regression Accuracy: 0.78\n",
      "Logistic Regression Precision: 0.755\n",
      "Logistic Regression Recall: 0.77\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prediction model using LogisticRegression\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "# Fit our data - Fit the model according to the given training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Record performance\n",
    "perf_record = [{'Model': 'LogisticRegression', \n",
    "         'Train Accuracy': np.around(pipe.score(X_train,y_train), decimals=3),\n",
    "         'Test Accuracy': np.around(metrics.accuracy_score(y_test, predicted), decimals=3),\n",
    "        'Test Precision': np.around(metrics.precision_score(y_test, predicted), decimals=3), \n",
    "         'Test Recall': np.around(metrics.recall_score(y_test, predicted), decimals=3)}]\n",
    "\n",
    "df_performance = df_performance.append(perf_record, ignore_index=True, sort=False)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Training Accuracy:\", np.around(pipe.score(X_train,y_train), decimals=3))\n",
    "print(\"Logistic Regression Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"Logistic Regression Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"Logistic Regression Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Training Accuracy: 0.907\n",
      "DecisionTreeClassifier Accuracy: 0.736\n",
      "DecisionTreeClassifier Precision: 0.711\n",
      "DecisionTreeClassifier Recall: 0.714\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prediction model using DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', DecisionTreeClassifier(random_state=0, min_samples_split = 150))])\n",
    "\n",
    "# Fit our data - Fit the model according to the given training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Record performance\n",
    "perf_record = [{'Model': 'DecisionTreeClassifier', \n",
    "         'Train Accuracy': np.around(pipe.score(X_train,y_train), decimals=3),\n",
    "         'Test Accuracy': np.around(metrics.accuracy_score(y_test, predicted), decimals=3),\n",
    "        'Test Precision': np.around(metrics.precision_score(y_test, predicted), decimals=3), \n",
    "         'Test Recall': np.around(metrics.recall_score(y_test, predicted), decimals=3)}]\n",
    "\n",
    "df_performance = df_performance.append(perf_record, ignore_index=True, sort=False)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"DecisionTreeClassifier Training Accuracy:\", np.around(pipe.score(X_train,y_train), decimals=3))\n",
    "print(\"DecisionTreeClassifier Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"DecisionTreeClassifier Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"DecisionTreeClassifier Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Training Accuracy: 0.993\n",
      "RandomForestClassifier Accuracy: 0.733\n",
      "RandomForestClassifier Precision: 0.708\n",
      "RandomForestClassifier Recall: 0.71\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prediction model using RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', RandomForestClassifier(n_estimators=100,oob_score=True))])\n",
    "\n",
    "# Fit our data - Fit the model according to the given training data.\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Record performance\n",
    "perf_record = [{'Model': 'RandomForestClassifier', \n",
    "         'Train Accuracy': np.around(pipe.score(X_train,y_train), decimals=3),\n",
    "         'Test Accuracy': np.around(metrics.accuracy_score(y_test, predicted), decimals=3),\n",
    "        'Test Precision': np.around(metrics.precision_score(y_test, predicted), decimals=3), \n",
    "         'Test Recall': np.around(metrics.recall_score(y_test, predicted), decimals=3)}]\n",
    "\n",
    "df_performance = df_performance.append(perf_record, ignore_index=True, sort=False)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"RandomForestClassifier Training Accuracy:\", np.around(pipe.score(X_train,y_train), decimals=3))\n",
    "print(\"RandomForestClassifier Accuracy:\", np.around(metrics.accuracy_score(y_test, predicted), decimals=3))\n",
    "print(\"RandomForestClassifier Precision:\", np.around(metrics.precision_score(y_test, predicted), decimals=3))\n",
    "print(\"RandomForestClassifier Recall:\", np.around(metrics.recall_score(y_test, predicted), decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Accuracy  Test Accuracy  Test Precision  \\\n",
       "0               LinearSVC           0.976          0.767           0.733   \n",
       "1      LogisticRegression           0.946          0.780           0.755   \n",
       "2  DecisionTreeClassifier           0.907          0.736           0.711   \n",
       "3  RandomForestClassifier           0.993          0.733           0.708   \n",
       "\n",
       "   Test Recall  \n",
       "0        0.774  \n",
       "1        0.770  \n",
       "2        0.714  \n",
       "3        0.710  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results of different models\n",
    "df_performance.plot(kind='bar', grid='on', x = 'Model', figsize = (14,6), ylim=(0.65,1.05),);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
